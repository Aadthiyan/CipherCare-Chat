# ğŸ¯ Permanent Patient Data: Two Approaches

## ğŸ“‹ The Problem

**Your Other Project (Documents):**
- Users upload documents â†’ Encrypted on upload â†’ Stored per user
- **Dynamic data** - changes with each upload

**This Project (Patient Records):**
- Patient data is **static** (pre-loaded dataset)
- Should be **permanent** (like a database)
- All users query the **same data**
- **Should NOT disappear** on restart

---

## âœ… Solution 1: Pre-load Data in Docker Image (RECOMMENDED)

### **Concept:**
Bake the patient data **into the Docker image** during build time, so it's always there.

### **How It Works:**
```
Docker Build Process:
1. Copy patient data JSON into image
2. Start CyborgDB temporarily
3. Load data into CyborgDB
4. Save CyborgDB data directory in image
5. Stop CyborgDB
6. Image now contains pre-loaded data!

Docker Run:
1. Start container
2. CyborgDB starts with data already loaded
3. Backend connects to CyborgDB
4. Data is immediately available!
```

### **Advantages:**
âœ… **Data is permanent** - Part of the image itself  
âœ… **No upload needed** - Data is there from the start  
âœ… **Works on free tier** - No persistent disk required  
âœ… **Fast startup** - Data already loaded  
âœ… **Consistent** - Every deployment has the same data  

### **Disadvantages:**
âš ï¸ **Larger image size** - ~500MB more (for embeddings)  
âš ï¸ **Longer build time** - ~10-15 minutes (one-time)  
âš ï¸ **To update data** - Must rebuild image  

### **Files Created:**
1. `docker/backend-with-preloaded-data.Dockerfile` - Dockerfile that pre-loads data
2. `scripts/preload_data.py` - Script that loads data during build

### **Deployment:**
```bash
# 1. Update render.yaml to use new Dockerfile
dockerfilePath: ./docker/backend-with-preloaded-data.Dockerfile

# 2. Remove persistent disk (not needed)
# disk:  # <-- Comment out or remove

# 3. Deploy
git add .
git commit -m "Pre-load patient data in Docker image"
git push

# 4. Data is automatically loaded during build!
```

---

## âœ… Solution 2: Persistent Disk with One-Time Upload

### **Concept:**
Use persistent disk storage, upload data once, it stays forever.

### **How It Works:**
```
First Deployment:
1. Deploy container with persistent disk
2. Upload data once via script
3. Data saved to persistent disk

Subsequent Deployments:
1. Container restarts
2. Mounts same persistent disk
3. Data is still there!
```

### **Advantages:**
âœ… **Data persists** - Survives restarts and redeployments  
âœ… **Can update data** - Without rebuilding image  
âœ… **Flexible** - Can add/remove data anytime  

### **Disadvantages:**
âš ï¸ **Requires Starter plan** - $7/month for persistent disk  
âš ï¸ **Manual upload needed** - After first deployment  
âš ï¸ **Upload complexity** - Need proxy or local setup  

### **Files:**
1. `docker/backend-with-cyborgdb.Dockerfile` - Current combined Dockerfile
2. `upload_sdk_fast.py` - Upload script

### **Deployment:**
```bash
# 1. Deploy with persistent disk (already done)
git push

# 2. Upload data once
python upload_sdk_fast.py  # Option 5

# 3. Data persists forever on disk
```

---

## ğŸ¯ Comparison

| Feature | Pre-loaded Image | Persistent Disk |
|---------|------------------|-----------------|
| **Data Persistence** | âœ… Always there | âœ… Survives restarts |
| **Setup Complexity** | ğŸŸ¡ Medium (build time) | ğŸŸ¡ Medium (upload) |
| **Cost** | âœ… Free tier OK | âš ï¸ $7/mo required |
| **Update Data** | âš ï¸ Rebuild image | âœ… Just re-upload |
| **Startup Time** | âœ… Instant | âœ… Instant |
| **Image Size** | âš ï¸ ~1.5GB | âœ… ~1GB |
| **Build Time** | âš ï¸ 10-15 min | âœ… 5 min |

---

## ğŸ’¡ My Recommendation

### **For Your Use Case:**

Since your patient data is:
- âœ… **Static** (doesn't change often)
- âœ… **Same for all users** (not per-user)
- âœ… **Critical** (must always be available)

**Use Solution 1: Pre-loaded Image** â­

This is the **most reliable** approach for static data that should always be there.

---

## ğŸš€ Implementation Guide

### **Option 1: Pre-loaded Image (Recommended)**

#### **Step 1: Update render.yaml**

```yaml
services:
  - type: web
    name: ciphercare-backend
    env: docker
    dockerfilePath: ./docker/backend-with-preloaded-data.Dockerfile  # Changed!
    dockerContext: .
    plan: free  # Can use free tier!
    healthCheckPath: /health
    # No disk needed - data is in the image!
    envVars:
      - key: CYBORGDB_BASE_URL
        value: http://localhost:8002
      - key: CYBORGDB_API_KEY
        value: cyborg_9e8c1c2e25c944d78f41ac7f23376d23  # Hardcoded for build
      # ... other env vars
```

#### **Step 2: Deploy**

```bash
git add .
git commit -m "Pre-load patient data in Docker image"
git push origin main
```

#### **Step 3: Wait for Build**

- Build will take ~10-15 minutes (one-time)
- Watch Render logs for:
  ```
  ğŸš€ Pre-loading Patient Data into CyborgDB
  âœ“ Loaded 76317 records
  âœ“ Found 150 unique patients
  ğŸ‰ SUCCESS! All 76317 records loaded into CyborgDB!
  ```

#### **Step 4: Test**

```bash
# Query should work immediately!
curl https://ciphercare-backend.onrender.com/api/v1/query \
  -H "Authorization: Bearer TOKEN" \
  -d '{"patient_id": "PID-101", "question": "What medications?"}'
```

---

### **Option 2: Persistent Disk**

#### **Step 1: Keep Current Setup**

Your current `render.yaml` with persistent disk is already correct.

#### **Step 2: Add Upload Proxy to Backend**

Since CyborgDB is on localhost:8002 inside the container, you need a proxy to upload from outside.

Add to `backend/main.py`:

```python
from fastapi import Request
from fastapi.responses import Response
import httpx

@app.api_route("/cyborgdb/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
async def cyborgdb_proxy(path: str, request: Request):
    """Proxy requests to internal CyborgDB"""
    url = f"http://localhost:8002/{path}"
    
    async with httpx.AsyncClient() as client:
        # Forward the request
        response = await client.request(
            method=request.method,
            url=url,
            content=await request.body(),
            headers=dict(request.headers)
        )
        
        return Response(
            content=response.content,
            status_code=response.status_code,
            headers=dict(response.headers)
        )
```

#### **Step 3: Upload Data**

```bash
# Update upload script to use proxy
CYBORGDB_BASE_URL=https://ciphercare-backend.onrender.com/cyborgdb

python upload_sdk_fast.py  # Option 5
```

---

## ğŸ¯ Final Recommendation

**Use Pre-loaded Image (Option 1)** because:

1. âœ… **Most reliable** - Data can never be lost
2. âœ… **Simpler** - No upload needed
3. âœ… **Cheaper** - Works on free tier
4. âœ… **Faster** - Data ready immediately
5. âœ… **Best for static data** - Perfect for your use case

The only downside is longer build time (~10-15 min), but this is a **one-time cost** and worth it for the reliability.

---

## ğŸ“‹ Next Steps

**I recommend:**

1. **Update `render.yaml`** to use `backend-with-preloaded-data.Dockerfile`
2. **Remove persistent disk** (not needed)
3. **Set `CYBORGDB_API_KEY` in render.yaml** (needed for build)
4. **Deploy** and watch the build logs
5. **Test** - data will be there immediately!

Would you like me to make these changes?

---

**Last Updated:** 2026-01-07  
**Status:** âœ… Ready to implement
